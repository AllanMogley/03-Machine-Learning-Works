{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIw0uuNkbgjj"
      },
      "source": [
        "### 1. Install PyTorch/XLA\n",
        "The PyTorch/XLA package lets PyTorch connect and manipulate tensors in Cloud TPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yckWOwmobgjk"
      },
      "outputs": [],
      "source": [
        "# Connect to a Cloud TPU which more powerfuls than a GPU\n",
        "# Make sure to select TPU from Edit > Notebook settings > Hardware accelerator\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt_FHeLzbgjl"
      },
      "outputs": [],
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision>=0.6.0"
      ],
      "metadata": {
        "id": "ShJM-s1UeMWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d1awxI9fbgjl"
      },
      "outputs": [],
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
        "device = xm.xla_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZlN1b5Ibgjm"
      },
      "source": [
        "### 2. Torch Libraries\n",
        "Load relevant libraries required to build the CNN network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DQQ6-QMIbgjm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZacFCV6bgjm"
      },
      "source": [
        "### 3. Data initialization\n",
        "Load and Initialize tha datasets to be used in training the model.\n",
        "\n",
        "Load the training dataset by setting split = 'train'. Load The testing dataset by setting split = 'test'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexTsgQUgB9D",
        "outputId": "171ed5cf-4b01-4759-e754-1ee9cd9c3b58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/02 - Project/03 - ML_WORKS/Data Files 2\n",
        "!dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfWbkHEVf-NB",
        "outputId": "861e4c60-9255-4397-8319-187c85476984"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/02 - Project/03 - ML_WORKS/Data Files 2\n",
            "instances_default.json\todm_orthophoto_0_0.tif\todm_orthophoto_0_1.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools"
      ],
      "metadata": {
        "id": "QIDwSsiyoz54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
      ],
      "metadata": {
        "id": "_e7o6cTNoys7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataDir='/content/drive/MyDrive/02 - Project/03 - ML_WORKS/Data Files 2'\n",
        "# dataType='val2017'\n",
        "annFile='{}/instances_default.json'.format(dataDir,dataType)"
      ],
      "metadata": {
        "id": "AaEmC3VGpC-p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize COCO api for instance annotations\n",
        "coco=COCO(annFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULDnw2ApY3I",
        "outputId": "d1d07907-a1da-4f30-8791-4ae906c45224"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display COCO categories and supercategories\n",
        "cats = coco.loadCats(coco.getCatIds())\n",
        "nms=[cat['name'] for cat in cats]\n",
        "print('COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
        "\n",
        "nms = set([cat['supercategory'] for cat in cats])\n",
        "print('COCO supercategories: \\n{}'.format(' '.join(nms)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTUz4ra7pxCj",
        "outputId": "3505daee-79cb-4dcf-bab2-40707949615c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COCO categories: \n",
            "Maize Grass VelvetLeaf Others\n",
            "\n",
            "COCO supercategories: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all images containing given categories, select one at random\n",
        "catIds = coco.getCatIds(catNms=['Maize','Grass','VelvetLeaf']);\n",
        "imgIds = coco.getImgIds(catIds=catIds );\n",
        "imgIds = coco.getImgIds(imgIds = [324158])\n",
        "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "v6leUDU5p8WV",
        "outputId": "d0a40216-0474-4218-b5af-21d07e4ccb39"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c25e2143acf5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimgIds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatIds\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimgIds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m324158\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36mloadImgs\u001b[0;34m(self, ids)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshowAnns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_bbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 324158"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsdbzAZGbgjm"
      },
      "outputs": [],
      "source": [
        "# Install datasets library\n",
        "# This libraries helps load already labeled dataseta from CIFAR-1- HuggingFace\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIG2nJ1xbgjn"
      },
      "outputs": [],
      "source": [
        "# import CIFAR-10 dataset from HuggingFace\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset(\n",
        "    'cifar10',\n",
        "    split='train[:1%]', # 1% training dataset\n",
        "    # split='train', # training dataset\n",
        "    ignore_verifications=True  # set to True if seeing splits Error\n",
        ")\n",
        "\n",
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL_bN5lJbgjn"
      },
      "outputs": [],
      "source": [
        "# check number of classes\n",
        "num_classes = len(set(dataset_train['label']))\n",
        "num_classes"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
<<<<<<< HEAD
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a Cloud TPU which more powerfuls than a GPU\n",
    "# Make sure to select TPU from Edit > Notebook settings > Hardware accelerator\n",
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports pytorch\n",
    "import torch\n",
    "\n",
    "# imports the torch_xla package\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
    "device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Torch Libraries\n",
    "Load relevant libraries required to build the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data initialization\n",
    "Load and Initialize tha datasets to be used in training the model.\n",
    "\n",
    "Load the training dataset by setting split = 'train'. Load The testing dataset by setting split = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install datasets library\n",
    "# This libraries helps load already labeled dataseta from CIFAR-1- HuggingFace\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CIFAR-10 dataset from HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_train = load_dataset(\n",
    "    'cifar10',\n",
    "    split='train[:1%]', # 1% training dataset\n",
    "    # split='train', # training dataset\n",
    "    ignore_verifications=True  # set to True if seeing splits Error\n",
    ")\n",
    "\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of classes\n",
    "num_classes = len(set(dataset_train['label']))\n",
    "num_classes\n",
    "\n",
    "# View an Image\n",
    "# dataset_train[0]['img']\n",
    "\n",
    "# Print Image type\n",
    "# type(dataset_train[0]['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in the Test set (To use as a validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = load_dataset(\n",
    "    'cifar10',\n",
    "    split='test[:1%]', # 10% test dataset\n",
    "    # split='test', # test dataset\n",
    "    ignore_verifications=True  # set to True if seeing splits Error\n",
    ")\n",
    "\n",
    "dataset_val"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
  "nbformat": 4,
  "nbformat_minor": 0
}
>>>>>>> c24ad33d9b11cf4b1e46c878e8d01b9fd7d35317
