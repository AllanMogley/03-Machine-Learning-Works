{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d0fa46a8",
      "metadata": {
        "id": "d0fa46a8"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/image-retrieval/cnn/cifar10.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/image-retrieval/cnn/cifar10.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b325e409-0b8c-4b80-a936-32b2b7002d68",
      "metadata": {
        "id": "b325e409-0b8c-4b80-a936-32b2b7002d68"
      },
      "source": [
        "### Generate Image Embeddings Using CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "001eb1ad-7172-4308-a87b-fd9c2ddb29aa",
      "metadata": {
        "id": "001eb1ad-7172-4308-a87b-fd9c2ddb29aa"
      },
      "source": [
        "In this section, we will use PyTorch to build a Convolutional Neural Network from scratch  that generates image embeddings.✔✔✔"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to a Cloud TPU which more powerfuls than a GPU\n",
        "# Make sure to select TPU from Edit > Notebook settings > Hardware accelerator\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']"
      ],
      "metadata": {
        "id": "6qx80CznSWWA"
      },
      "id": "6qx80CznSWWA",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing PyTorch/XLA\n",
        "The PyTorch/XLA package lets PyTorch connect to Cloud TPUs. (It's named PyTorch/XLA, not PyTorch/TPU, because XLA is the name of the TPU compiler.) In particular, PyTorch/XLA makes TPU cores available as PyTorch devices. This lets PyTorch create and manipulate tensors on TPUs."
      ],
      "metadata": {
        "id": "Qyk7jhndTPFC"
      },
      "id": "Qyk7jhndTPFC"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "SpkWCzNGTb0-"
      },
      "id": "SpkWCzNGTb0-",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating and Manipulating Tensors on TPUs\n",
        "\n",
        "PyTorch uses Cloud TPUs just like it uses CPU or CUDA devices, as the next few cells will show. Each core of a Cloud TPU is treated as a different PyTorch  device."
      ],
      "metadata": {
        "id": "os6jOAiQTqxV"
      },
      "id": "os6jOAiQTqxV"
    },
    {
      "cell_type": "code",
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
        "device = xm.xla_device()"
      ],
      "metadata": {
        "id": "_Nxll__dTy1X"
      },
      "id": "_Nxll__dTy1X",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2271958e-cf71-4df8-a3b8-a736dd9c98f7",
      "metadata": {
        "id": "2271958e-cf71-4df8-a3b8-a736dd9c98f7"
      },
      "source": [
        "#### Data Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b5121d0-9e68-4c12-98c5-3132bac48b24",
      "metadata": {
        "id": "0b5121d0-9e68-4c12-98c5-3132bac48b24"
      },
      "source": [
        "Before starting, below are some libraries we would need to build the convolutional network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "747eefd9-2d8d-4b1e-8f04-6e1f62b603e7",
      "metadata": {
        "id": "747eefd9-2d8d-4b1e-8f04-6e1f62b603e7"
      },
      "outputs": [],
      "source": [
        "# Load in relevant libraries, and alias where appropriate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5685d59c-987a-4c9d-af1b-8a9be1ca505b",
      "metadata": {
        "id": "5685d59c-987a-4c9d-af1b-8a9be1ca505b"
      },
      "source": [
        "Given we will be working with a reasonable amount of data, we might want to process it on GPU rather than CPU. To do that, we need to transfer the data from CPU to GPU using ```torch.device```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "50974897-8297-49ed-a3a4-ae09d704313f",
      "metadata": {
        "id": "50974897-8297-49ed-a3a4-ae09d704313f"
      },
      "outputs": [],
      "source": [
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4d1a1a-c55f-40ce-a4df-6ee38875b45d",
      "metadata": {
        "id": "3b4d1a1a-c55f-40ce-a4df-6ee38875b45d"
      },
      "source": [
        "The first step in building our network is downloading and initializing the dataset.\n",
        "\n",
        "The dataset we are downloading is *CIFAR-10* from HuggingFace.\n",
        "\n",
        "We will first download the training dataset by setting ```split = 'train'```, and the testing dataset after by setting ''split = 'test'```. While the training dataset includes 50,000 images divided into 10 classes, the test dataset includes 10,000 images divided into 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install datasets library\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "2SyyLvchWqvB"
      },
      "id": "2SyyLvchWqvB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "87510a3c-9382-4a39-a39b-ded727bf6f1d",
      "metadata": {
        "id": "87510a3c-9382-4a39-a39b-ded727bf6f1d",
        "outputId": "4da09f22-8969-4f6f-ff87-081b764a02cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147,
          "referenced_widgets": [
            "a79def2685584afc8ba28dd9903308bb"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a79def2685584afc8ba28dd9903308bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cifar10 downloaded and prepared to /root/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['img', 'label'],\n",
              "    num_rows: 5000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# import CIFAR-10 dataset from HuggingFace\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset_train = load_dataset(\n",
        "    'cifar10',\n",
        "    split='train[:10%]', # 10% training dataset\n",
        "    # split='train', # training dataset\n",
        "    ignore_verifications=True  # set to True if seeing splits Error\n",
        ")\n",
        "\n",
        "dataset_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8df80571-3e94-492c-8750-898464f7092c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8df80571-3e94-492c-8750-898464f7092c",
        "outputId": "29e2a068-82eb-4172-cec2-8c4fa46dc45e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# check how many labels/number of classes\n",
        "num_classes = len(set(dataset_train['label']))\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a5cc6158-181b-4790-92b2-073670bfc975",
      "metadata": {
        "id": "a5cc6158-181b-4790-92b2-073670bfc975",
        "outputId": "26f6dadc-0e40-4bc3-e6ea-252cb6070bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F0DAAAC1540>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAH8klEQVR4nHVWS68dRxGuqn7MnDkz53UfwdzEQgSEEsdCihSJLRKIn8KGHX8MwYIVGwRS2CQECSlRYsy149j3Xp/HnDNnpqe7q4rFwcaJRKvVqq6u/r6vululxt//7k/wqiEigAIoIsL/b6r6pvFqqqpw6iIiwiLMzJaIVF8hIiIogL4J9x2y18H/2/UGkyqoIiIi6mnRMvO3UfRNQEQUEURQhdMIAIggJ0u/m8fJLaIiIiKqSq/jAABRTzpO0CmlrutOK6/okEWGIfR9fzz2J1nfEvffE1YiOvntKdMxhO1uwyqXF5feOVXNnF/c3kwn1XQ6PVGKyEnp3fpldzwu54tpVTHzawIBUOHNZt227Wp5Nq1rALAIGFP86vGjJ8+eKMBPHzy8uvd9MrTbt4+vr3/8w3dPClSViG5f3qWURCWEYX7/fozx5ubGWnt5cWG9e3l3e3397+1m3ff9Yr56+MHDqqrss2+ePXn29G5zF9MIgI8ePzoej9O62m7XLze3rDzGIAqL+Xw5n68367v1unT22Pfdfj+m+OLutq4bAQlxfPny7vrJ9RizAEyqJKoIiL/+zW9DGIwhBCAkYS58ASCJx8RSWF8V1aEfp5NyNqu37f4YRkIForPlqu9aREC0232bU64mhUEKfRTRh+89WJyvYorWoS4vz/f7w6HrSu+dIeaUUET1rK6naMcshTUied/tvXf3Lt8qCndo2/bQjmFoCgekVenZGlZpJsVbswYFQYbHT764ubuznty0nPSHHoEuzlZ1WW13u8PYHzkNx76oKlHxjqp66r1HkTT2OeiExTuno2HRUUZQEElZ+NALAiDQYRO33X4YBouZU9dbxKauJmVpLBmLZ8V0lotDe2QW620a03DsIBVGdDf0ibn07rKq31mdDSkdlLPw0/bGGgPKN7t2GOOibqbFxBtrl7OaCSbolmXFKQxJQxxZdV6WYkzLXIlNLKEP63RABTfxdVWy5IOIMzQIl0XZxyAMGYA5xZwzS4rReduNo51eXmx3e0WDzk9KNco5hpggsk6c89aiqvXGkt9qQLJNM00xiUIGUZVuHIuiWDT1vXuXSaTdbEi5tCQ577qui9EaY2LOOStLsiSQQ8o8qcpuyDnngjCmXE/L89XCHw5A5nJ19vxuPYY4KSfOmv44kDVIVLnST4rxeDx2R+9NyGlIkJnttmuFREkF9DAMm/WdClRVrIpi1jQiHFPeh3TMrXG2tHa72XLOInI4dMYSEj57/mI2nzEz9zmEITMXgCpCCARgl1VtWLPJRVl4v1yv1zEmhNEZo4UW5SRkHmMOQ7g4XyHQs5vn/RhndV14e2yPfRj6IYjwbFYfDp0hOlvMC+cRAQhE1BpnACFlNlmaabGom+BDymmIQVl8EVXUO9dMJ6W1YewvLs/b/SGEYQhgyNRVUU8nhMQpzZv5crEahmNOUQFzZs7Jqoh3zhAVRQHAhlg4obJB5wtrDQiCSs4x70MvqsZQ6cx2108KX1YVC6eUAYCZc46SYBxH4QxIqmiMtaoQhhhjGsc0nzUqyHlUFbQ29IO8quWqAISoqqDCGQSHkBIfVDTnbIz1zvX9LrMoKPOpPgpntjlxHHMfRj7I7c1huwlZRzTEmoA5s6ScrbOgYJHcGMFiKux0MgVDIYyl9yIqkp2xgFAUJmURlbqqrDEibFVVQdbr7aNHT1WtpXo2nyyWxMIpR0O2JJwVE6eqqnUEX03h6gKNsc6klKqy6IdRBLyzaMBbG8YYwricz+p6IiLWWHP51vl0Wt3erNfb4/lZUcc8bmFx1VTTlSGSIUuI2veJcMCMFs8Wc1Xw3lRlgYgiqgAGEQgRUVQ5Ze+stZaFrYgwc92UH3308JNPPgcXcRh3Ldl68fDBT5ar2X7b/uOzTwOBEIIntrBgRkVni8nEqwIiiQqRQ0RFAQF1zCoCqog25xxjOgaeNtXVvfNP/v6VFW9NefN19/GfH//8lx++98GDt++/k7MoIGv2zs2bGSBaa5ylnKUfxrqaxLE3gFhWzDnHFMZhv9/t91vbdV3f94eud95Yn5u6GHpzdtFcXV3ePh/++Ie/3X93+Ytf/ezsrAYwqgKoCJiFVSAxHA7Dx3/9bHm+yk+ufzRzzQfvm/NzY33tCrLFGNnu2w0irRZNCOH5dlcvidx40/7r6/UX/ZHHMX/6uT6/u/7ww/dnzXTWzJz1dHqCrIf+sNt3L7cvHl8/cuMYbCjbjf/BfWOMsS6zGGOsMdYYMs6eNZdFUTlvRXiz3m7b9ng8Hocxx/zN86f7v2zPV8vFYsGi3jkEUBVCFGGgCGYYS/hnVr/dVqFXAmadNzNrjFUwMcvtNy8AoPKOiJpqagnfefteXTfdoYt53Ky3Ctq1uy+/fLTZ7VarZemcMfTO1dVsVjOPbbsh8kRgEdViVlnv2nldA4Jtuzal1IeBVClZJZI0JNCwH7rjXjgjQDVx1lrvyFpaLabL+dx7r6DWqGgmgu9dniERCDhUIEKlWVO17ZoQbe0Ii/KsqQjAEACSijIqqKoIWUuAqiCqflLOJwXiOQICABIioKg4QPBeVdAaRAhx5BS9AUkRkSykqIgAyKCKqK+/kCcYUAZFBAKE0+8URQFVFE9RqioMCKJCaBANCZOoApAKiNghDsxiyGaNpKAIgOjIEKpotmhz5owyxOTJO2MVGBRUQFAJIQsjIYugmtPNK0hmQQEkEOH/AIgrr0LkBku7AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# let's view the image (it's very small)\n",
        "dataset_train[0]['img']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ba410153-e667-4e75-953e-fa3969568139",
      "metadata": {
        "id": "ba410153-e667-4e75-953e-fa3969568139",
        "outputId": "bb709c28-6d5d-44af-bac1-c46ebfd30e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PIL.PngImagePlugin.PngImageFile"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(dataset_train[0]['img'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ffafa0e-7189-420f-9a9a-01fe33ed195a",
      "metadata": {
        "id": "9ffafa0e-7189-420f-9a9a-01fe33ed195a"
      },
      "source": [
        "Now pull in the test set (that we will use as a validation set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c419b9b4-13a1-4a21-8dfd-7d083f893220",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c419b9b4-13a1-4a21-8dfd-7d083f893220",
        "outputId": "e1cc40bb-d653-42df-efd9-1d542a4ac4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset cifar10 (/root/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['img', 'label'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dataset_val = load_dataset(\n",
        "    'cifar10',\n",
        "    split='test[:10%]', # 10% test dataset\n",
        "    # split='test', # test dataset\n",
        "    ignore_verifications=True  # set to True if seeing splits Error\n",
        ")\n",
        "\n",
        "dataset_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ad0341-9989-4ddc-88a7-4ee31d9136d3",
      "metadata": {
        "id": "40ad0341-9989-4ddc-88a7-4ee31d9136d3"
      },
      "source": [
        "Most convolutional neural networks are designed so that they can only accept images of a fixed size. It's common practice to overcome this by reshaping the input images.\n",
        "\n",
        "We chose to reshape the image to 32 pixels - see ```img_size```.\n",
        "\n",
        "In addition, PyTorch uses tensors.\n",
        "\n",
        "Therefore, we will transform the data using the ```transforms.Compose``` method, and save the reshaped tensors in the ```preprocess``` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a4d7c395-5424-4296-9b9b-f78ee9d08695",
      "metadata": {
        "id": "a4d7c395-5424-4296-9b9b-f78ee9d08695"
      },
      "outputs": [],
      "source": [
        "# image size\n",
        "img_size = 32\n",
        "\n",
        "# preprocess variable, to be used ahead\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((img_size,img_size)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df4d64ee-c5e5-4dfe-829c-35b0080c1ea0",
      "metadata": {
        "id": "df4d64ee-c5e5-4dfe-829c-35b0080c1ea0"
      },
      "source": [
        "We can now use the ```preprocess``` variable on the dataset with the following loop. However, when we build a cnn, we should ensure every image has the same number of input channels (or depth). This is because the input dimension to the cnn cannot change.\n",
        "\n",
        "If we have RGB images, the depth will be $3$, with one channel for each color (red, green, and blue). If we have grayscale images, the depth will be $1$.\n",
        "\n",
        "In case the dataset contains images with different number of channels, we should convert them from grayscale to RGB (or the other way round). When an image is in grayscale, its ```mode``` is `L`. Otherwise, the mode is `RGB`.\n",
        "\n",
        "We then converted the images to RGB and preprocessed them in the same loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5d55444c-60ec-4913-9771-93db4824b91d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2a3ae79d42c94a80ba24d0e3051a39e5",
            "85c731b79e7d47bf8178018476801a7b",
            "e4012598e0d4499f816d586b552b52cd",
            "af76fddb14c9481f9d386783c97630b5",
            "2b2fb6a1f269499f9961b6c035d3f68e",
            "eb269a8f7ae54051b85cd68a1244b7d9",
            "e427daa9f30148de817281a09ab0741d",
            "1c7c1afb40264152afd551b1aa3dad4c",
            "c2a7618d6caf497caaf284c799709fa0",
            "a9aadb6c61d54d7db4121cc99bf844c3",
            "d931887fe3564837aeeb6e1daf628add"
          ]
        },
        "id": "5d55444c-60ec-4913-9771-93db4824b91d",
        "outputId": "539fd2f6-d283-48a7-ca09-f2223e7e8964"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a3ae79d42c94a80ba24d0e3051a39e5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "inputs_train = []\n",
        "\n",
        "for record in tqdm(dataset_train):\n",
        "    image = record['img']\n",
        "    label = record['label']\n",
        "\n",
        "    # convert from grayscale to RGB\n",
        "    if image.mode == 'L':\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # prepocessing\n",
        "    input_tensor = preprocess(image)\n",
        "\n",
        "    # append to batch list\n",
        "    inputs_train.append([input_tensor, label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3eaf6075",
      "metadata": {
        "id": "3eaf6075",
        "outputId": "83ea8bf5-0096-4795-9b26-6f787b3c7394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 torch.Size([3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "print(len(inputs_train), inputs_train[0][0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34234565-ff48-4333-8070-2786f0a6873d",
      "metadata": {
        "id": "34234565-ff48-4333-8070-2786f0a6873d"
      },
      "source": [
        "Below we can see the result from the transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "69c256c0-8607-4d30-81ee-c7589e181eba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69c256c0-8607-4d30-81ee-c7589e181eba",
        "outputId": "1741f96e-1070-489e-a3b9-ad7a5c865fca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[0.6980, 0.6980, 0.6980,  ..., 0.6667, 0.6588, 0.6471],\n",
              "          [0.7059, 0.7020, 0.7059,  ..., 0.6784, 0.6706, 0.6588],\n",
              "          [0.6941, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6549],\n",
              "          ...,\n",
              "          [0.4392, 0.4431, 0.4471,  ..., 0.3922, 0.3843, 0.3961],\n",
              "          [0.4392, 0.4392, 0.4431,  ..., 0.4000, 0.4000, 0.4000],\n",
              "          [0.4039, 0.3922, 0.4039,  ..., 0.3608, 0.3647, 0.3569]],\n",
              " \n",
              "         [[0.6902, 0.6902, 0.6902,  ..., 0.6588, 0.6510, 0.6392],\n",
              "          [0.6980, 0.6941, 0.6980,  ..., 0.6706, 0.6627, 0.6510],\n",
              "          [0.6863, 0.6863, 0.6902,  ..., 0.6627, 0.6549, 0.6471],\n",
              "          ...,\n",
              "          [0.4196, 0.4275, 0.4314,  ..., 0.3804, 0.3686, 0.3725],\n",
              "          [0.4000, 0.4039, 0.4039,  ..., 0.3725, 0.3647, 0.3608],\n",
              "          [0.3765, 0.3647, 0.3725,  ..., 0.3294, 0.3373, 0.3294]],\n",
              " \n",
              "         [[0.7412, 0.7412, 0.7412,  ..., 0.7059, 0.6941, 0.6824],\n",
              "          [0.7490, 0.7451, 0.7490,  ..., 0.7137, 0.7059, 0.6941],\n",
              "          [0.7373, 0.7373, 0.7412,  ..., 0.7059, 0.6980, 0.6902],\n",
              "          ...,\n",
              "          [0.4196, 0.4235, 0.4314,  ..., 0.3686, 0.3647, 0.3725],\n",
              "          [0.3961, 0.4000, 0.4039,  ..., 0.3647, 0.3569, 0.3569],\n",
              "          [0.3608, 0.3529, 0.3686,  ..., 0.3137, 0.3137, 0.3020]]]),\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "inputs_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4daa892-7cad-4548-9cee-babf173ae32d",
      "metadata": {
        "id": "f4daa892-7cad-4548-9cee-babf173ae32d"
      },
      "source": [
        "The tensors are normalized to a \\[0, 1\\] range by the `preprocess` pipeline thanks to the `transforms.ToTensor()` function. We need to modify this normalization slightly to fit this specific dataset. To do this, we need the mean and standard deviation values for each of the RGB channels across all images.\n",
        "\n",
        "We calculate that like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1a0a938f-49aa-4daf-a018-e33ae705308e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a0a938f-49aa-4daf-a018-e33ae705308e",
        "outputId": "58ac4b49-c753-4c09-b24f-24ae418db1aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# calculate mean and std of images, first start by choosing a random sample of tensors\n",
        "idx = np.random.randint(0, len(inputs_train), 512)\n",
        "idx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7346e4a6-1dce-4e25-9f1c-b50841506947",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7346e4a6-1dce-4e25-9f1c-b50841506947",
        "outputId": "d5c51e94-a5fa-4295-ba44-77d1a569ec12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 16384, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# then we concatenate this subset of image tensors\n",
        "tensors = torch.concat([inputs_train[i][0] for i in idx], axis=1)\n",
        "tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a0ac48ca-28d6-406b-bdcc-e90ec3cfa068",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ac48ca-28d6-406b-bdcc-e90ec3cfa068",
        "outputId": "b5eda50e-b9ce-4595-dc42-7656490c2841"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([524288, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# merge all values into single 3-channel vector\n",
        "tensors = tensors.swapaxes(0, 1).reshape(3, -1).T\n",
        "tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "19c3a7f7-a4a5-4170-9809-118bbf0de5ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c3a7f7-a4a5-4170-9809-118bbf0de5ad",
        "outputId": "4a4ec48b-01bd-48f7-d4d3-ee8f5d2f8a96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4670, 0.4735, 0.4662])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "mean = torch.mean(tensors, axis=0)\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4a1552eb-38ca-4022-95e7-48290efaa8e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a1552eb-38ca-4022-95e7-48290efaa8e4",
        "outputId": "940e23e1-0d32-493f-efa0-5e532fa99f72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2496, 0.2489, 0.2521])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "std = torch.std(tensors, axis=0)\n",
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5eb0368f-23c4-4f36-a6a2-14438fdec124",
      "metadata": {
        "id": "5eb0368f-23c4-4f36-a6a2-14438fdec124"
      },
      "outputs": [],
      "source": [
        "del tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f6d4ae1-69a6-4f98-b457-f2c43093bb38",
      "metadata": {
        "id": "9f6d4ae1-69a6-4f98-b457-f2c43093bb38"
      },
      "source": [
        "Now we use the `mean` $[0.4670, 0.4735, 0.4662]$ and `std` $[0.2496, 0.2489, 0.2521]$ to normalize via another preprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "81cfbe6a-05fc-40c3-9136-dcecc7c36840",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bd2468f3a58a493d87161a7a0fc5d376",
            "01b1e8f0ec3f4efdaef95d7f4f4f4dae",
            "aa46ae1d532f4441a9b75459eb7e00a9",
            "e66247dda96540cfb600fb9c0b063ac8",
            "528e9a63841a43ab9840eeee1b6a9d2a",
            "1fa7489159dd43b7ad83ddf142fb0b23",
            "20ea4934863140808d3761ab66a3f283",
            "a7a4082e3b084c97b58e727258b6e28f",
            "33fe03dc93644962b92f96c0194030e1",
            "5ac173637eaa413c912bef34e0d88cfe",
            "a4c49b49146b4ac89b009cb936c67c92"
          ]
        },
        "id": "81cfbe6a-05fc-40c3-9136-dcecc7c36840",
        "outputId": "8ba8572b-0a93-4c12-e2d7-c6aa17765feb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd2468f3a58a493d87161a7a0fc5d376"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "preprocess = transforms.Compose([transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "for i in tqdm(range(len(inputs_train))):\n",
        "    # prepocessing\n",
        "    input_tensor = preprocess(inputs_train[i][0])\n",
        "    inputs_train[i][0] = input_tensor  # replace with normalized tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c55406-6f60-427e-b9dc-1f040d49c286",
      "metadata": {
        "id": "e1c55406-6f60-427e-b9dc-1f040d49c286"
      },
      "source": [
        "We can merge the preprocessing steps as follows,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "88dd5eb8-33cb-48b6-9021-b979ec6ac102",
      "metadata": {
        "id": "88dd5eb8-33cb-48b6-9021-b979ec6ac102"
      },
      "outputs": [],
      "source": [
        "# merge the two preprocessing steps from before\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((img_size,img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0692ef00-7f2a-4917-9c90-21cc09bc8588",
      "metadata": {
        "id": "0692ef00-7f2a-4917-9c90-21cc09bc8588"
      },
      "source": [
        "and we can apply the same transformation to the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "931fa393-df08-4d54-95d6-0e2b4047d29c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2f2ef3197a084318ae8205a6a4743a85",
            "9a8b79a9cf2d46df9cb06562cfa7a830",
            "3e17a0e617b54663b09899f31907fe8b",
            "dcf9d4b99a7c4b5d8cff1a408cb7520f",
            "2f3345a4b33744d5842c0a1513108b28",
            "6f0f08af0f3a4d0f9c5d9b14361c2a22",
            "c7fe047ea37f434f972d19019cff964a",
            "0b25fdc804694f0ea0863d32643adac0",
            "8e94bc2c793c4c8c91ce97a0c760be2d",
            "1abf0f617e47406d8d66841ea9678ed8",
            "c6cf5e0f809a46dfb6549c3cf64e5f92"
          ]
        },
        "id": "931fa393-df08-4d54-95d6-0e2b4047d29c",
        "outputId": "762dc8b2-4be3-4006-bba6-cc47ec5e2c10"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f2ef3197a084318ae8205a6a4743a85"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "inputs_val = []\n",
        "i = 0\n",
        "for record in tqdm(dataset_val):\n",
        "    image = record['img']\n",
        "    label = record['label']\n",
        "\n",
        "    # convert from grayscale to RBG\n",
        "    if image.mode == 'L':\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # prepocessing\n",
        "    input_tensor = preprocess(image)\n",
        "    inputs_val.append((input_tensor, label)) # append to batch list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b242ba-7621-4eae-a16c-b0d52a1e8418",
      "metadata": {
        "id": "28b242ba-7621-4eae-a16c-b0d52a1e8418"
      },
      "source": [
        "Given the amount of data, we would improve the efficiency of our model by running it in batches. We can set the batch size to $64$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1391456a-1ba6-42ab-9782-d1758e1fc849",
      "metadata": {
        "id": "1391456a-1ba6-42ab-9782-d1758e1fc849"
      },
      "outputs": [],
      "source": [
        "# define batch size\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b054f679-71f8-439c-9d29-6c63ae876d94",
      "metadata": {
        "id": "b054f679-71f8-439c-9d29-6c63ae876d94"
      },
      "source": [
        "We can then use ```DataLoader``` to split both the training and validation dataset into shuffled batches. Shuffle helps prevent model overfitting by ensuring that batches are more representative of the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a1a68ebd-6fe9-4e00-8471-4ff5174277ff",
      "metadata": {
        "id": "a1a68ebd-6fe9-4e00-8471-4ff5174277ff"
      },
      "outputs": [],
      "source": [
        "dloader_train = torch.utils.data.DataLoader(\n",
        "    inputs_train, batch_size=batch_size, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8d4f6f12-de4c-4f2b-948b-e64466dbcb2b",
      "metadata": {
        "id": "8d4f6f12-de4c-4f2b-948b-e64466dbcb2b"
      },
      "outputs": [],
      "source": [
        "dloader_val = torch.utils.data.DataLoader(\n",
        "    inputs_val, batch_size=batch_size, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a694096-4a99-49a5-9fae-76c826282ee6",
      "metadata": {
        "id": "4a694096-4a99-49a5-9fae-76c826282ee6"
      },
      "source": [
        "#### Building the CNN's Structure/Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ef12b6-9cf6-4345-814b-05f231e2b5a6",
      "metadata": {
        "id": "09ef12b6-9cf6-4345-814b-05f231e2b5a6"
      },
      "source": [
        "We can now start building our cnn by generating the `ConvNeuralNet` class and the `forward` function. The `ConvNeuralNet` class defines the elements inside our network. The `forward` function establishes their order:\n",
        "\n",
        "- The first two blocks of layers are composed of a convolutional layer followed by a max-pooling layer. After each convolutional layer, we added non-linearity using the ReLU activation function.\n",
        "\n",
        "- The following two blocks of layers are composed of a convolutional layer followed by the ReLU activation function.\n",
        "\n",
        "- We then have another block composed of one convolutional layer, followed by the ReLU, followed by the max pooling layer.\n",
        "\n",
        "At each block, the images are downsampled by the max-pooling layer. Contrary, the number of channels from one layer to another increased from $3$ to $64$, to $192$, ..., to $256$. As we learned before, deeper layers have larger receptive fields and generally detect more specific and complex features, such as ears, eyes, or even human faces and dogs. The chosen filter (or kernel) size is either $3$ or $4$. This is a common choice - having a smaller filter allows the network to better generalize. Padding is $1$ pixel on each layer.\n",
        "\n",
        "- In the end, we have three fully-connected layers. The first two are activated using the ReLU, and the last one uses the Softmax.\n",
        "\n",
        "Note that we added `dropout`. It randomly zeroes (or \"drops out\") some of the elements of the input tensor with a probability $p = 25\\%$. This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons as described in the paper Improving neural networks by preventing co-adaptation of feature detectors [1].\n",
        "\n",
        "\n",
        "We can represent our network as follows:\n",
        "\n",
        "[image]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d41b3a3d-34fc-42f2-8fd1-fd1c4cd09b22",
      "metadata": {
        "id": "d41b3a3d-34fc-42f2-8fd1-fd1c4cd09b22"
      },
      "outputs": [],
      "source": [
        "# creating a CNN class\n",
        "class ConvNeuralNet(nn.Module):\n",
        "\t#  determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=4, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.conv_layer5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.max_pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        self.dropout6 = nn.Dropout(p=0.5)\n",
        "        self.fc6 = nn.Linear(1024, 512)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.dropout7 = nn.Dropout(p=0.5)\n",
        "        self.fc7 = nn.Linear(512, 256)\n",
        "        self.relu7 = nn.ReLU()\n",
        "        self.fc8 = nn.Linear(256, num_classes)\n",
        "\n",
        "    # progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.relu4(out)\n",
        "\n",
        "        out = self.conv_layer5(out)\n",
        "        out = self.relu5(out)\n",
        "        out = self.max_pool5(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = self.dropout6(out)\n",
        "        out = self.fc6(out)\n",
        "        out = self.relu6(out)\n",
        "\n",
        "        out = self.dropout7(out)\n",
        "        out = self.fc7(out)\n",
        "        out = self.relu7(out)\n",
        "\n",
        "        out = self.fc8(out)  # final logits\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "202dbd79-0a54-4a06-84c3-036b9b4b7550",
      "metadata": {
        "id": "202dbd79-0a54-4a06-84c3-036b9b4b7550"
      },
      "source": [
        "After setting the architecture of our network, we can define the loss function, which is calculated after the forward propagation. We will then define the optimization methodology to run the backpropagation.\n",
        "\n",
        "The loss function used is cross-entropy.\n",
        "\n",
        "The model optimization is run using the stochastic gradient descent (SGD) method with a learning rate equal to $0.008$. Training under SGD, the network is forced to learn to extract features from the image that minimize the loss for extracting features that are the most useful for classifying or recognising images.\n",
        "The learning rate can be chosen randomly by running the model using different values and selecting the one that gives the best performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f37c0a86-e5bb-466c-b7d4-714d731dcaa3",
      "metadata": {
        "id": "f37c0a86-e5bb-466c-b7d4-714d731dcaa3"
      },
      "outputs": [],
      "source": [
        "# set the model to device\n",
        "model = ConvNeuralNet(num_classes).to(device)\n",
        "\n",
        "# set Loss function with criterion\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# set learning rate\n",
        "lr = 0.008  # 0.0001\n",
        "\n",
        "# set optimizer with optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "#total_step = len(dloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ffd8888-9195-4463-aa83-aa93ed4a585d",
      "metadata": {
        "id": "4ffd8888-9195-4463-aa83-aa93ed4a585d"
      },
      "source": [
        "We are now ready to train our model with the forward and the backward propagation in batches. We are now using the `device` variable created above to move the data to GPU, if possible.\n",
        "\n",
        "We have set the times the learning algorithm will work through the entire training dataset (epochs) to 50. As per the learning rate, there is no rule for choosing this value. You can run the model many times with different values and choose the one with the sufficiently minimized error.\n",
        "\n",
        "It is also essential to not choose a number of `epochs` (or `lr`) that causes the model to overfit the training set. To check this, we include a pass through the validation set after each epoch, calculating the val-loss and val-accuracy. If we see the validation set performance degrades while train loss decreases, the model is likely overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3027a649-cd51-4c79-a672-2d6d372c1873",
      "metadata": {
        "tags": [],
        "id": "3027a649-cd51-4c79-a672-2d6d372c1873"
      },
      "outputs": [],
      "source": [
        "# train and validate the network\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\t# load in the data in batches\n",
        "    for i, (images, labels) in enumerate(dloader_train):\n",
        "        # move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward propagation\n",
        "        outputs = model(images)\n",
        "        loss = loss_func(outputs, labels)\n",
        "\n",
        "        # backward propagation and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # at end of epoch check validation loss and accuracy on validation set\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_val_loss = []\n",
        "        for images, labels in dloader_val:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            total += labels.size(0)\n",
        "            # calculate predictions\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            # calculate actual values\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            # calculate the loss\n",
        "            all_val_loss.append(loss_func(outputs, labels).item())\n",
        "        # calculate val-loss\n",
        "        mean_val_loss = sum(all_val_loss) / len(all_val_loss)\n",
        "        # calculate val-accuracy\n",
        "        mean_val_acc = 100 * (correct / total)\n",
        "\n",
        "    print(\n",
        "        'Epoch [{}/{}], Loss: {:.4f}, Val-loss: {:.4f}, Val-acc: {:.1f}%'.format(\n",
        "            epoch+1, num_epochs, loss.item(), mean_val_loss, mean_val_acc\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c310d89-2083-482b-a9f4-bf59041de8c2",
      "metadata": {
        "id": "6c310d89-2083-482b-a9f4-bf59041de8c2"
      },
      "source": [
        "The network is now trained and tested! The network validation accuracy is $79.4\\%$. We can go ahead and save the model to file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05989bae",
      "metadata": {
        "id": "05989bae"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'cnn.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb707d56-7c01-47d1-a06d-cfb2bcac2e4c",
      "metadata": {
        "id": "fb707d56-7c01-47d1-a06d-cfb2bcac2e4c"
      },
      "source": [
        "---\n",
        "\n",
        "# Inference\n",
        "\n",
        "Now we will look at how to make predictions with the model. We start by loading the model from file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de3b2496",
      "metadata": {
        "id": "de3b2496"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model = torch.load('cnn.pt')\n",
        "# switch to evaluation mode and device\n",
        "model.eval().to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73553acc-9fb3-41e5-ba2a-dd575f58a14e",
      "metadata": {
        "id": "73553acc-9fb3-41e5-ba2a-dd575f58a14e"
      },
      "source": [
        "We will reinitialize the CIFAR-10 test set to similate a typical scenario where we would need to reload everything. Ideally we would not use the validation set as a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7463c3a9-33e5-4917-8f56-dbbbe55ab4af",
      "metadata": {
        "id": "7463c3a9-33e5-4917-8f56-dbbbe55ab4af"
      },
      "outputs": [],
      "source": [
        "# import CIFAR-10 dataset from HuggingFace\n",
        "from datasets import load_dataset\n",
        "\n",
        "data_test = load_dataset(\n",
        "    'cifar10',\n",
        "    split='test'  # test set\n",
        ")\n",
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b144865d-c66d-4121-8925-a84cdb6574f0",
      "metadata": {
        "id": "b144865d-c66d-4121-8925-a84cdb6574f0"
      },
      "outputs": [],
      "source": [
        "input_tensors = []\n",
        "for image in data_test['img'][:10]:\n",
        "    tensor = preprocess(image)\n",
        "    input_tensors.append(tensor.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d315e65-658b-4fa3-8c96-93eb9a05a8fe",
      "metadata": {
        "id": "2d315e65-658b-4fa3-8c96-93eb9a05a8fe"
      },
      "outputs": [],
      "source": [
        "# we have 10 tensors\n",
        "len(input_tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12e0287-5d66-44a4-8a19-144fb5dba9c5",
      "metadata": {
        "id": "d12e0287-5d66-44a4-8a19-144fb5dba9c5"
      },
      "outputs": [],
      "source": [
        "# all 32x32 dimensional with 3 color channels\n",
        "input_tensors[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16ed9a7e-85cb-4c8b-9dd3-a878d2478437",
      "metadata": {
        "id": "16ed9a7e-85cb-4c8b-9dd3-a878d2478437"
      },
      "source": [
        "We stack these into a single tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225dfd48-5a59-4b09-9e71-a0b7be377676",
      "metadata": {
        "id": "225dfd48-5a59-4b09-9e71-a0b7be377676"
      },
      "outputs": [],
      "source": [
        "# stack into a single tensor\n",
        "input_tensors = torch.stack(input_tensors)\n",
        "input_tensors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1a6d62-96f1-4436-8175-7e98788f8aa8",
      "metadata": {
        "id": "7c1a6d62-96f1-4436-8175-7e98788f8aa8"
      },
      "outputs": [],
      "source": [
        "# process through model to get output logits\n",
        "outputs = model(input_tensors)\n",
        "# calculate predictions\n",
        "predicted = torch.argmax(outputs, dim=1)\n",
        "predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "476f030e-3da1-40ac-a935-1a2961d8da2a",
      "metadata": {
        "id": "476f030e-3da1-40ac-a935-1a2961d8da2a"
      },
      "outputs": [],
      "source": [
        "predicted.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b15f4b77-8670-4c2d-b8e5-9d19d6b94da5",
      "metadata": {
        "id": "b15f4b77-8670-4c2d-b8e5-9d19d6b94da5"
      },
      "outputs": [],
      "source": [
        "# here are the class names\n",
        "data_test.features['label'].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be8f514-150f-4700-98e7-7968fc54f6c7",
      "metadata": {
        "id": "9be8f514-150f-4700-98e7-7968fc54f6c7"
      },
      "outputs": [],
      "source": [
        "data_test[1]['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4ebfdc-c24f-4e6f-9437-38a1694d0943",
      "metadata": {
        "id": "4b4ebfdc-c24f-4e6f-9437-38a1694d0943"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i, image in enumerate(data_test['img'][:10]):\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    print(data_test.features['label'].names[predicted[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4aca325-39d3-4289-a616-3e09f7704590",
      "metadata": {
        "id": "a4aca325-39d3-4289-a616-3e09f7704590"
      },
      "source": [
        "Most of these predictions look correct, despite being very low resolution images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29b2684-2626-4027-9ecf-28779b17ac67",
      "metadata": {
        "id": "f29b2684-2626-4027-9ecf-28779b17ac67"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cu110.m95",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cu110:m95"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe10bf018ef3e697f9035d60bf60847932a12bface18908407fd371fe880db9"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a3ae79d42c94a80ba24d0e3051a39e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85c731b79e7d47bf8178018476801a7b",
              "IPY_MODEL_e4012598e0d4499f816d586b552b52cd",
              "IPY_MODEL_af76fddb14c9481f9d386783c97630b5"
            ],
            "layout": "IPY_MODEL_2b2fb6a1f269499f9961b6c035d3f68e"
          }
        },
        "85c731b79e7d47bf8178018476801a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb269a8f7ae54051b85cd68a1244b7d9",
            "placeholder": "​",
            "style": "IPY_MODEL_e427daa9f30148de817281a09ab0741d",
            "value": "100%"
          }
        },
        "e4012598e0d4499f816d586b552b52cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7c1afb40264152afd551b1aa3dad4c",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2a7618d6caf497caaf284c799709fa0",
            "value": 50000
          }
        },
        "af76fddb14c9481f9d386783c97630b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9aadb6c61d54d7db4121cc99bf844c3",
            "placeholder": "​",
            "style": "IPY_MODEL_d931887fe3564837aeeb6e1daf628add",
            "value": " 50000/50000 [00:49&lt;00:00, 686.32it/s]"
          }
        },
        "2b2fb6a1f269499f9961b6c035d3f68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb269a8f7ae54051b85cd68a1244b7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e427daa9f30148de817281a09ab0741d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7c1afb40264152afd551b1aa3dad4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a7618d6caf497caaf284c799709fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9aadb6c61d54d7db4121cc99bf844c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d931887fe3564837aeeb6e1daf628add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd2468f3a58a493d87161a7a0fc5d376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01b1e8f0ec3f4efdaef95d7f4f4f4dae",
              "IPY_MODEL_aa46ae1d532f4441a9b75459eb7e00a9",
              "IPY_MODEL_e66247dda96540cfb600fb9c0b063ac8"
            ],
            "layout": "IPY_MODEL_528e9a63841a43ab9840eeee1b6a9d2a"
          }
        },
        "01b1e8f0ec3f4efdaef95d7f4f4f4dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fa7489159dd43b7ad83ddf142fb0b23",
            "placeholder": "​",
            "style": "IPY_MODEL_20ea4934863140808d3761ab66a3f283",
            "value": "100%"
          }
        },
        "aa46ae1d532f4441a9b75459eb7e00a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a4082e3b084c97b58e727258b6e28f",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33fe03dc93644962b92f96c0194030e1",
            "value": 50000
          }
        },
        "e66247dda96540cfb600fb9c0b063ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac173637eaa413c912bef34e0d88cfe",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c49b49146b4ac89b009cb936c67c92",
            "value": " 50000/50000 [00:04&lt;00:00, 15069.85it/s]"
          }
        },
        "528e9a63841a43ab9840eeee1b6a9d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa7489159dd43b7ad83ddf142fb0b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ea4934863140808d3761ab66a3f283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7a4082e3b084c97b58e727258b6e28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fe03dc93644962b92f96c0194030e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ac173637eaa413c912bef34e0d88cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c49b49146b4ac89b009cb936c67c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2ef3197a084318ae8205a6a4743a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a8b79a9cf2d46df9cb06562cfa7a830",
              "IPY_MODEL_3e17a0e617b54663b09899f31907fe8b",
              "IPY_MODEL_dcf9d4b99a7c4b5d8cff1a408cb7520f"
            ],
            "layout": "IPY_MODEL_2f3345a4b33744d5842c0a1513108b28"
          }
        },
        "9a8b79a9cf2d46df9cb06562cfa7a830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0f08af0f3a4d0f9c5d9b14361c2a22",
            "placeholder": "​",
            "style": "IPY_MODEL_c7fe047ea37f434f972d19019cff964a",
            "value": "100%"
          }
        },
        "3e17a0e617b54663b09899f31907fe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b25fdc804694f0ea0863d32643adac0",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e94bc2c793c4c8c91ce97a0c760be2d",
            "value": 10000
          }
        },
        "dcf9d4b99a7c4b5d8cff1a408cb7520f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1abf0f617e47406d8d66841ea9678ed8",
            "placeholder": "​",
            "style": "IPY_MODEL_c6cf5e0f809a46dfb6549c3cf64e5f92",
            "value": " 10000/10000 [00:10&lt;00:00, 1227.82it/s]"
          }
        },
        "2f3345a4b33744d5842c0a1513108b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0f08af0f3a4d0f9c5d9b14361c2a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7fe047ea37f434f972d19019cff964a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b25fdc804694f0ea0863d32643adac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e94bc2c793c4c8c91ce97a0c760be2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1abf0f617e47406d8d66841ea9678ed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cf5e0f809a46dfb6549c3cf64e5f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}